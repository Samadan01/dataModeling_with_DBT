{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling with DBT\n",
    "\n",
    "This Project demonstrates how to model a dataset based on two multi-dimensional data models such as the Star Schema and One Big Table (OBT).\n",
    "\n",
    "In order to follow along on this project, an IDE connected to a server is needed, also a database is needed with a JDBC configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [ 1 - Introduction and Setup](#1)\n",
    "  - [ 1.1 - Initiating dbt 101 Project](#1-1)\n",
    "  - [ 1.2 - Source Configuration](#1-2)\n",
    "- [ 2 - Modeling](#2)\n",
    "- [ 3 - Star Schema](#3)\n",
    "  - [ 3.1 - Description of the Approach](#3-1)\n",
    "  - [ 3.2 - Creating the Facts Table](#3-2)\n",
    "  - [ 3.3 - Creating the Customers Dimension Table](#3-3)\n",
    "  - [ 3.4 - Creating the Employees Dimension Table](#3-4)\n",
    "  - [ 3.5 - Creating the Office Dimension Table](#3-5)\n",
    "  - [ 3.6 - Creating the Product Dimension Table](#3-6)\n",
    "  - [ 3.7 - Creating the Date Dimension Table](#3-7)\n",
    "  - [ 3.8 - Running the Star Schema Model](#3-8)\n",
    "- [ 4 - One Big Table (OBT)](#4)\n",
    "- [ 5 - Performing Tests over the Data in the New Models](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, load the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1 - Introduction and Setup\n",
    "\n",
    "Data modeling is one of the pillars of Data Engineering, it involves organizing bits of data into defined models with their respective data types and relationships between each other. Most of the work in data modeling involves using predefined techniques or patterns on a raw dataset based on the business's requirements. Data models like the **Star Schema** and **One Big Table (OBT)** have become popular for analytical workloads in recent years. In this project, I apply these models to the `classicmodels` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1-1'></a>\n",
    "### 1.1 - Initiating **dbt 101** Project\n",
    "\n",
    "**dbt** is a transformation workflow command line tool based on SQL, it consists of a compiler and a runner. A user writes `dbt` files and then can invoke `dbt` to run these files on the data warehouse of their choice. The compiler converts the `dbt` files into raw SQL scripts and runs them ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Let's start a `dbt` project."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.1. Run the following command in the terminal to check that `dbt` Core is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt --version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.2. Initiate the `classicmodels_modeling` project with the `init` command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt init classicmodels_modeling\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the `postgres` database by pressing `1` and then `Enter` when prompted to. After that you will be prompted to enter other values, but you should quit that with `Cmd + C` or `Ctrl + C` as you will configure the rest of the connection details later. Check that the folder `classicmodels_modeling` will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.3. Copy the `packages.yml` file to the project folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cp ./scripts/packages.yml ./classicmodels_modeling/\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.4. Navigate into your project's directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd classicmodels_modeling\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.5. Run the following command from the `classicmodels_modeling` folder to fetch the latest stable versions of tools and libraries specified in the `packages.yml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt deps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.6. Open the main configuration file for the project `./classicmodels_modeling/dbt_project.yml`. Go through the comments in that file to understand its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1-2'></a>\n",
    "### 1.2 - Source Configuration\n",
    "\n",
    "When developing with `dbt Core`, `dbt` connects to the data warehouse using a profile, which is a `YAML` file with all the connection details to the warehouse. You are going to use a Postgres database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "1.2.1. Run the following code to get the link to the AWS console.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://signin.aws.amazon.com/federation?Action=login&SigninToken=oonTJLnQBHb-QSwuKVgbRNEHVMdQA3nvKJe-5fDCu-3NYDyuq23P2tsfPJ2JZ2CMNGS0eJiJBmEjZeic5DRRm4qTVOaI5Zr7ZAnxh5NRpcgFvCuU4P-K0WJW6XYVUcGTLke-vCFdTdqfgoM5dvmm_b5sZ3hztb2D3lZktS6EJYP1QDyv3FoX4g0iNwWFLF5KInfaI7VmBh5kd6hdUchlu0sqlicI9diKWgAM4-6bRvo5lk3nEFFAlkNA4Kl5b1Fwl86F_D1gdGEGYOJJkpiOD8VK-Zmw6n0UsDxzZTIP6BQFe5lHNIAgbtJ9w9oZzSFgu7TrD3yjRhxv7LYOroEKHrpVfMzY6U8Opw5EdFcvb2F30xvetwabNCMQ3-pRaNxdYohiQencc8OnqU1A4jb1upp38lsjazPVxK3lenbQ1LHsi3xTdgU7oavrxxfAoHyb2cxTU_EV2g7fes7TXO1nhEERna34MjYQlQwfJ4dlnP87SEHe43nzfKub3KUMntlEqEkJ-3_vTiWIBjdzYDYU7feC053q-X_HfQEnTLAQaF0aMd5RRpQ1Rd578kLGhvoGi7akn_Ca-FooYKsof4wT_euZdWyOsjjMyfBLbUoJ8eRtDpXqt1Ch5cVG4WNVfXk4LeiPBFT53GB0EnEfaLuIQF-f_lfeXrM_gKsC665x68PXwNCEMEmbkjV0rPt_l7WaIsuInkRthvQM6zmhGL3ZPziqNmj85pred1MML-_9Oy1g9uwxcIL6r16ZCFXSOhrFlB5iLuyalyuTNlW1BDTGxI8O0r4CPWGlic450Wn1gBnu44GnoXEAN-j54GHCqsaIrWJ_EkKoIPUD_4CO2npSYPMiJMA8CMHS-1_vBv6_9QlPxqGO_vwiohzZrdm2fZrcvLAPcm7iJnznbzMeFECtlAAaq7b4LxX3nv7z4UPf5jXq9_lQD0HrF0zHxUS3ckUcimDNAryxUoUoRfmfoJAqz3lL0k9rQxHyaQ7lRRetzB0vv1AhXqP6nOhz90s5q3m559zDBVQsI5_yJArYd-6EaHP-V5k71s47Ev8IykyuE2dvg6hdI-YfQAcwYtaJ_awckydNWpXlWkKiEd3VglOrJSBYW72FEObU-ezC7sHetleWz0GVQKXE6JSFf-Un2vkMhBZv3ISobLmL6gKpk01UpfE0mn0oiA0J2RNoc_Fv-cZtd7QIoYVCWL9cD3UHu8VOd8YxvSirSJ9Cxb1oMmew3HOoARotRLq5dAqKr4Tm0YKlUOrjRgYcaq6X658sAxiApkxCMvnJmnOHqEQMM-67P9dhIZ9bLHDs_21eqisd0N9PlL0QcsXfhmbSd_yieSBZcSGCYS3bgkavHNPuFNV83WNgo9l_6Oi68YQ24An6DcpbIgSfIJrK7VKJTeUjxpdyJngos5JPONtbnGE_j9gg4SL7UJbqHNdlgQzxSBNInTlcyZLAnLKdjG0&Issuer=https%3A%2F%2Fapi.vocareum.com&Destination=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fregion%3Dus-east-1\" target=\"_blank\">GO TO AWS CONSOLE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../.aws/aws_console_url', 'r') as file:\n",
    "    aws_url = file.read().strip()\n",
    "\n",
    "HTML(f'<a href=\"{aws_url}\" target=\"_blank\">GO TO AWS CONSOLE</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to **CloudFormation** in the AWS console. Click on the alphanumeric stack name and search for the **Outputs** tab. You will see the key `PostgresEndpoint`, copy the corresponding **Value**. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.2. Open the file located at `./scripts/profiles.yml`. Replace the placeholders `<DATABASE_ENDPOINT>` with the endpoint value. Save changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.3. Assuming you are already inside the `classicmodels_modeling` folder in the terminal, run the following command to copy the `profiles.yml` file to the invisible folder `.dbt` of the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cp ../scripts/profiles.yml ~/.dbt/profiles.yml \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: If you received a message saying that there's no directory labelled `.dbt`, make sure to re-run the command in step 1.1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.4. Test the connection with the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt debug\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should return a `Connection test: OK connection ok` at the end of the output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.5. Load the connection configuration into the notebook with the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"./scripts/profiles.yml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "    \n",
    "DBCONFIG = data_loaded[\"classicmodels_modeling\"][\"outputs\"][\"dev\"]\n",
    "DBHOST = DBCONFIG[\"host\"]\n",
    "DBPORT = int(DBCONFIG[\"port\"])\n",
    "DBNAME = DBCONFIG[\"dbname\"]\n",
    "DBUSER = DBCONFIG[\"user\"]\n",
    "DBPASSWORD = DBCONFIG[\"password\"]\n",
    "db_connection_url = f'postgresql+psycopg2://{DBUSER}:{DBPASSWORD}@{DBHOST}:{DBPORT}/{DBNAME}'\n",
    "\n",
    "%sql {db_connection_url}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2 - Modeling\n",
    "\n",
    "Inside the `classicmodels_modeling` project folder, you have the `models` folder, which contains an example of a model definition. Let's explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2-4'></a>\n",
    "2.1. I created two new subfolders in the `models` folder inside the project: `star_schema` and `obt`.\n",
    "\n",
    "```bash\n",
    "mkdir -p models/star_schema\n",
    "mkdir -p models/obt\n",
    "rm -rf models/example\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 - Star Schema\n",
    "\n",
    "<a id='3-1'></a>\n",
    "### 3.1 - Description of the Approach\n",
    "\n",
    "**A star schema** is composed of **fact** tables (containing an identifier, numerical measures and foreign keys) and dimensional tables. I implemented the improved star schema as a `dbt` model in the project.\n",
    "\n",
    "Let's remember the Entity Relationship Diagram (ERD) for [`classicmodels`](https://www.mysqltutorial.org/mysql-sample-database.aspx):\n",
    "\n",
    "![erm](images/erm.png)\n",
    "\n",
    "Verify the tables are loaded into the source database in Postgres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>table_catalog</th>\n",
       "        <th>table_schema</th>\n",
       "        <th>table_name</th>\n",
       "        <th>table_type</th>\n",
       "        <th>self_referencing_column_name</th>\n",
       "        <th>reference_generation</th>\n",
       "        <th>user_defined_type_catalog</th>\n",
       "        <th>user_defined_type_schema</th>\n",
       "        <th>user_defined_type_name</th>\n",
       "        <th>is_insertable_into</th>\n",
       "        <th>is_typed</th>\n",
       "        <th>commit_action</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>employees</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>offices</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>customers</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>orderdetails</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>productlines</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>products</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>orders</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels</td>\n",
       "        <td>payments</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('postgres', 'classicmodels', 'employees', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'offices', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'customers', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'orderdetails', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'productlines', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'products', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'orders', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels', 'payments', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM information_schema.tables \n",
    "WHERE table_schema = 'classicmodels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a brief summary, I explain how to use the four steps proposed in the book [The Data Warehouse Toolkit](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/) by Ralph Kimball and Margy Ross. Feel free to skip this section if you are familiar with modelling a 3rd Normalized Schema to Star Schema, but if you'd like a review, here are the steps:\n",
    "- Select the Business process.\n",
    "- Declare the Granularity of your data.\n",
    "- Identify the Dimensions Tables.\n",
    "- Identify the Facts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly describe each of those steps:\n",
    "\n",
    "**Select the Business process**\n",
    "\n",
    "The original ERM of the `classicmodels` database is where the company, a specialist retailer in scale model toys, draws its data from. The most important business activity for this company is the sales of their products captured in the orders placed by customers, the business process you will model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare the Granularity of your data**\n",
    "\n",
    "Each order contains some details that appear in the `orderdetails` table. A customer can place an order for one or more product items. The `orderNumber` field in the `orderdetails` table together with the `productCode` links a product to the order; and the granularity of your model would allow access to product information for each item on that order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify the dimensions**\n",
    "\n",
    "It is important for a business to hold information about its customers, and the employees who serve the customer, their branches/offices and the products sold. These data would shed insights into the business’s performance. So, let’s create dimensions tables in your start schema with those aspects:\n",
    "\n",
    "- Customers Dimension\n",
    "- Employees Dimension\n",
    "- Offices Dimension\n",
    "- Products Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify the Facts**\n",
    "\n",
    "For each order placed by a customer, the unit price and quantity of a product ordered are important as they are used to calculate the sale total of this single order. Hence, this information from the `orderdetails` table should be included as facts in the fact table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the considerations stated in the four-step process to develop the star schema the idea is that you I implement the following model to the available data:\n",
    "\n",
    "![star_schema](images/star_schema.png)\n",
    "\n",
    "In this star schema, I did identified the orders table and order details as the primary tables for modeling, as they contain a business-critical process that involves **facts** such as transaction amounts and quantities. The dimensional tables related to the fact table are customers, products, employees and offices. So I did examine and perform aggregations to the fact table on either or multiples of these dimensions.\n",
    "\n",
    "Now, Let implement the proposed data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-2'></a>\n",
    "### 3.2 - Creating the Facts Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1. Review the query that extracts the data for the fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>ordernumber</th>\n",
       "        <th>orderlinenumber</th>\n",
       "        <th>customer_key</th>\n",
       "        <th>employee_key</th>\n",
       "        <th>office_key</th>\n",
       "        <th>product_key</th>\n",
       "        <th>order_date</th>\n",
       "        <th>order_required_date</th>\n",
       "        <th>order_shipped_date</th>\n",
       "        <th>quantity_ordered</th>\n",
       "        <th>product_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10100</td>\n",
       "        <td>3</td>\n",
       "        <td>363</td>\n",
       "        <td>1216</td>\n",
       "        <td>2</td>\n",
       "        <td>S18_1749</td>\n",
       "        <td>2003-01-06 00:00:00</td>\n",
       "        <td>2003-01-13 00:00:00</td>\n",
       "        <td>2003-01-10 00:00:00</td>\n",
       "        <td>30</td>\n",
       "        <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10100</td>\n",
       "        <td>2</td>\n",
       "        <td>363</td>\n",
       "        <td>1216</td>\n",
       "        <td>2</td>\n",
       "        <td>S18_2248</td>\n",
       "        <td>2003-01-06 00:00:00</td>\n",
       "        <td>2003-01-13 00:00:00</td>\n",
       "        <td>2003-01-10 00:00:00</td>\n",
       "        <td>50</td>\n",
       "        <td>55.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10100</td>\n",
       "        <td>4</td>\n",
       "        <td>363</td>\n",
       "        <td>1216</td>\n",
       "        <td>2</td>\n",
       "        <td>S18_4409</td>\n",
       "        <td>2003-01-06 00:00:00</td>\n",
       "        <td>2003-01-13 00:00:00</td>\n",
       "        <td>2003-01-10 00:00:00</td>\n",
       "        <td>22</td>\n",
       "        <td>75.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10100</td>\n",
       "        <td>1</td>\n",
       "        <td>363</td>\n",
       "        <td>1216</td>\n",
       "        <td>2</td>\n",
       "        <td>S24_3969</td>\n",
       "        <td>2003-01-06 00:00:00</td>\n",
       "        <td>2003-01-13 00:00:00</td>\n",
       "        <td>2003-01-10 00:00:00</td>\n",
       "        <td>49</td>\n",
       "        <td>35.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10101</td>\n",
       "        <td>4</td>\n",
       "        <td>128</td>\n",
       "        <td>1504</td>\n",
       "        <td>7</td>\n",
       "        <td>S18_2325</td>\n",
       "        <td>2003-01-09 00:00:00</td>\n",
       "        <td>2003-01-18 00:00:00</td>\n",
       "        <td>2003-01-11 00:00:00</td>\n",
       "        <td>25</td>\n",
       "        <td>108.06</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(10100, 3, 363, 1216, '2', 'S18_1749', datetime.datetime(2003, 1, 6, 0, 0), datetime.datetime(2003, 1, 13, 0, 0), datetime.datetime(2003, 1, 10, 0, 0), 30, Decimal('136')),\n",
       " (10100, 2, 363, 1216, '2', 'S18_2248', datetime.datetime(2003, 1, 6, 0, 0), datetime.datetime(2003, 1, 13, 0, 0), datetime.datetime(2003, 1, 10, 0, 0), 50, Decimal('55.09')),\n",
       " (10100, 4, 363, 1216, '2', 'S18_4409', datetime.datetime(2003, 1, 6, 0, 0), datetime.datetime(2003, 1, 13, 0, 0), datetime.datetime(2003, 1, 10, 0, 0), 22, Decimal('75.46')),\n",
       " (10100, 1, 363, 1216, '2', 'S24_3969', datetime.datetime(2003, 1, 6, 0, 0), datetime.datetime(2003, 1, 13, 0, 0), datetime.datetime(2003, 1, 10, 0, 0), 49, Decimal('35.29')),\n",
       " (10101, 4, 128, 1504, '7', 'S18_2325', datetime.datetime(2003, 1, 9, 0, 0), datetime.datetime(2003, 1, 18, 0, 0), datetime.datetime(2003, 1, 11, 0, 0), 25, Decimal('108.06'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    orders.orderNumber, orderdetails.orderLineNumber,\n",
    "    customers.customerNumber AS customer_key, \n",
    "    employees.employeeNumber AS employee_key,\n",
    "    offices.officeCode AS office_key,\n",
    "    productCode AS product_key, \n",
    "    orders.orderDate AS order_date,\n",
    "    orders.requiredDate AS order_required_date, \n",
    "    orders.shippedDate AS order_shipped_date,\n",
    "    orderdetails.quantityOrdered AS quantity_ordered, \n",
    "    orderdetails.priceEach AS product_price\n",
    "FROM classicmodels.orders\n",
    "JOIN classicmodels.orderdetails ON orders.orderNumber = orderdetails.orderNumber\n",
    "JOIN classicmodels.customers ON orders.customerNumber = customers.customerNumber\n",
    "JOIN classicmodels.employees ON customers.salesRepEmployeeNumber = employees.employeeNumber\n",
    "JOIN classicmodels.offices ON employees.officeCode = offices.officeCode\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.2.2. Now I need to create the `dbt` model for the `fact_orders` table. Open the `./classicmodels_modeling/dbt_project.yml` file and paste the following in the new line after `version: '1.0.0'`:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "vars:\n",
    "  source_schema: classicmodels\n",
    "  star_schema: classicmodels_star_schema\n",
    "  surrogate_key_treat_nulls_as_empty_strings: true\n",
    "  \"dbt_date:time_zone\": \"America/Los_Angeles\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for creation of some [variables](https://docs.getdbt.com/reference/dbt-jinja-functions/var) that can be used throughout your `dbt` models during compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.2.3. I did add to the configuration of `classicmodels_modeling` at the end of the file (nested under the `models` key). I deleted the nested key `example`, which is the following two lines:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "    example:\n",
    "      +materialized: view\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Then I did replace it with the following configuration:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "    star_schema:\n",
    "      +materialized: table\n",
    "      +schema: star_schema\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Then I save the changes."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.4. Go to the folder `./classicmodels_modeling/models/star_schema/` (which was created at step [2.4](#2.4)) and create an SQL file named `fact_orders.sql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.5 Copy the previous query for the fact table (without the `%%sql` and `LIMIT` clause) and paste it into a new file located at `fact_orders.sql`. Make the following changes:\n",
    "\n",
    "- Replace every appearance of `classicmodels` with `{{var(\"source_schema\")}}` (in 5 places). Each table reference in your query should now be in the format `{{var(\"source_schema\")}}.<TABLE_NAME>`. This will use jinja templating to dynamically replace `source_schema` with the actual schema name, which is currently `classicmodels`.\n",
    "- Replace the default key columns with surrogate keys using the `{{ dbt_utils.generate_surrogate_key(['']) }}` function. This function accepts an array of column names to generate the surrogate keys:\n",
    "    * Replace `orders.orderNumber, orderdetails.orderLineNumber` with `{{ dbt_utils.generate_surrogate_key(['orders.orderNumber', 'orderdetails.orderLineNumber']) }} as fact_order_key`.\n",
    "    * Replace `customers.customerNumber` with `{{ dbt_utils.generate_surrogate_key(['customers.customerNumber']) }}`.\n",
    "    * Do the same for `employees.employeeNumber`, `offices.officeCode` and `productCode`.\n",
    "\n",
    "Save changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.6. Copy the file located at `./scripts/schema.yml` into `./classicmodels_modeling/models/star_schema/` folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cp ../scripts/schema.yml ./models/star_schema/schema.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the `schema.yml` file. Observe the schema definition for the `fact_orders` and `dim_customers` tables.\n",
    "\n",
    "With this configuration, which was used in creating the model for the fact table `fact_orders`. Before I run the model against the database to create the tables, I did create the dimension tables. The process to create the models for the dimension tables is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-3'></a>\n",
    "### 3.3 - Creating the Customers Dimension Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.3.1. Here is the query to create the dimension table `dim_customers`. The complete output has 122 rows, I use `LIMIT` to avoid extracting too many rows in the preview."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>customer_key</th>\n",
       "        <th>customer_name</th>\n",
       "        <th>customer_last_name</th>\n",
       "        <th>customer_first_name</th>\n",
       "        <th>phone</th>\n",
       "        <th>address_line_1</th>\n",
       "        <th>address_line_2</th>\n",
       "        <th>postal_code</th>\n",
       "        <th>city</th>\n",
       "        <th>state</th>\n",
       "        <th>country</th>\n",
       "        <th>credit_limit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>103</td>\n",
       "        <td>Atelier graphique</td>\n",
       "        <td>Schmitt</td>\n",
       "        <td>Carine </td>\n",
       "        <td>40.32.2555</td>\n",
       "        <td>54, rue Royale</td>\n",
       "        <td>None</td>\n",
       "        <td>44000</td>\n",
       "        <td>Nantes</td>\n",
       "        <td>None</td>\n",
       "        <td>France</td>\n",
       "        <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>112</td>\n",
       "        <td>Signal Gift Stores</td>\n",
       "        <td>King</td>\n",
       "        <td>Jean</td>\n",
       "        <td>7025551838</td>\n",
       "        <td>8489 Strong St.</td>\n",
       "        <td>None</td>\n",
       "        <td>83030</td>\n",
       "        <td>Las Vegas</td>\n",
       "        <td>NV</td>\n",
       "        <td>USA</td>\n",
       "        <td>71800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>114</td>\n",
       "        <td>Australian Collectors, Co.</td>\n",
       "        <td>Ferguson</td>\n",
       "        <td>Peter</td>\n",
       "        <td>03 9520 4555</td>\n",
       "        <td>636 St Kilda Road</td>\n",
       "        <td>Level 3</td>\n",
       "        <td>3004</td>\n",
       "        <td>Melbourne</td>\n",
       "        <td>Victoria</td>\n",
       "        <td>Australia</td>\n",
       "        <td>117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>119</td>\n",
       "        <td>La Rochelle Gifts</td>\n",
       "        <td>Labrune</td>\n",
       "        <td>Janine </td>\n",
       "        <td>40.67.8555</td>\n",
       "        <td>67, rue des Cinquante Otages</td>\n",
       "        <td>None</td>\n",
       "        <td>44000</td>\n",
       "        <td>Nantes</td>\n",
       "        <td>None</td>\n",
       "        <td>France</td>\n",
       "        <td>118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>121</td>\n",
       "        <td>Baane Mini Imports</td>\n",
       "        <td>Bergulfsen</td>\n",
       "        <td>Jonas </td>\n",
       "        <td>07-98 9555</td>\n",
       "        <td>Erling Skakkes gate 78</td>\n",
       "        <td>None</td>\n",
       "        <td>4110</td>\n",
       "        <td>Stavern</td>\n",
       "        <td>None</td>\n",
       "        <td>Norway</td>\n",
       "        <td>81700</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(103, 'Atelier graphique', 'Schmitt', 'Carine ', '40.32.2555', '54, rue Royale', None, '44000', 'Nantes', None, 'France', Decimal('21000')),\n",
       " (112, 'Signal Gift Stores', 'King', 'Jean', '7025551838', '8489 Strong St.', None, '83030', 'Las Vegas', 'NV', 'USA', Decimal('71800')),\n",
       " (114, 'Australian Collectors, Co.', 'Ferguson', 'Peter', '03 9520 4555', '636 St Kilda Road', 'Level 3', '3004', 'Melbourne', 'Victoria', 'Australia', Decimal('117300')),\n",
       " (119, 'La Rochelle Gifts', 'Labrune', 'Janine ', '40.67.8555', '67, rue des Cinquante Otages', None, '44000', 'Nantes', None, 'France', Decimal('118200')),\n",
       " (121, 'Baane Mini Imports', 'Bergulfsen', 'Jonas ', '07-98 9555', 'Erling Skakkes gate 78', None, '4110', 'Stavern', None, 'Norway', Decimal('81700'))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    customerNumber as customer_key, \n",
    "    customerName as customer_name,   \n",
    "    contactLastName as customer_last_name, \n",
    "    contactFirstName as customer_first_name, \n",
    "    phone as phone, \n",
    "    addressLine1 as address_line_1, \n",
    "    addressLine2 as address_line_2, \n",
    "    postalCode as postal_code, \n",
    "    city as city, \n",
    "    state as state, \n",
    "    country as country,\n",
    "    creditLimit as credit_limit\n",
    "FROM classicmodels.customers\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the same process to create this part in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2. Go to the folder `./classicmodels_modeling/models/star_schema/` and create an SQL file `dim_customers.sql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.3. Copy the previous query without the `%%sql` and `LIMIT` clause, paste it into the new file `dim_customers.sql`. Make the following changes in the file:\n",
    "\n",
    "- Replace `classicmodels` with `{{var(\"source_schema\")}}` (in 1 place). The table reference now is in the format `{{var(\"source_schema\")}}.<TABLE_NAME>`. \n",
    "- Replace `customerNumber` with `{{ dbt_utils.generate_surrogate_key(['customerNumber']) }}` to generate the surrogate key.\n",
    "\n",
    "Save changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-4'></a>\n",
    "### 3.4 - Creating the Employees Dimension Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.4.1. Here is the query to create the dimension table `dim_employees`. I use a `LIMIT` to avoid extracting too many rows. The complete output has 23 rows."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>employee_key</th>\n",
       "        <th>employee_last_name</th>\n",
       "        <th>employee_first_name</th>\n",
       "        <th>job_title</th>\n",
       "        <th>email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1002</td>\n",
       "        <td>Murphy</td>\n",
       "        <td>Diane</td>\n",
       "        <td>President</td>\n",
       "        <td>dmurphy@classicmodelcars.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1056</td>\n",
       "        <td>Patterson</td>\n",
       "        <td>Mary</td>\n",
       "        <td>VP Sales</td>\n",
       "        <td>mpatterso@classicmodelcars.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1076</td>\n",
       "        <td>Firrelli</td>\n",
       "        <td>Jeff</td>\n",
       "        <td>VP Marketing</td>\n",
       "        <td>jfirrelli@classicmodelcars.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1088</td>\n",
       "        <td>Patterson</td>\n",
       "        <td>William</td>\n",
       "        <td>Sales Manager (APAC)</td>\n",
       "        <td>wpatterson@classicmodelcars.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1102</td>\n",
       "        <td>Bondur</td>\n",
       "        <td>Gerard</td>\n",
       "        <td>Sale Manager (EMEA)</td>\n",
       "        <td>gbondur@classicmodelcars.com</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1002, 'Murphy', 'Diane', 'President', 'dmurphy@classicmodelcars.com'),\n",
       " (1056, 'Patterson', 'Mary', 'VP Sales', 'mpatterso@classicmodelcars.com'),\n",
       " (1076, 'Firrelli', 'Jeff', 'VP Marketing', 'jfirrelli@classicmodelcars.com'),\n",
       " (1088, 'Patterson', 'William', 'Sales Manager (APAC)', 'wpatterson@classicmodelcars.com'),\n",
       " (1102, 'Bondur', 'Gerard', 'Sale Manager (EMEA)', 'gbondur@classicmodelcars.com')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    employeeNumber as employee_key,\n",
    "    lastName as employee_last_name, \n",
    "    firstName as employee_first_name, \n",
    "    jobTitle as job_title, \n",
    "    email as email\n",
    "FROM classicmodels.employees\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.2. Go to the folder `./classicmodels_modeling/models/star_schema/` and create an SQL file `dim_employees.sql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.3. Copy the previous query without the `%%sql` and `LIMIT` clause, and paste it into the new file `dim_employees.sql`. Make the following changes in the file:\n",
    "\n",
    "- Replace `classicmodels` with `{{var(\"source_schema\")}}` (in 1 place).\n",
    "- Replace `employeeNumber` with `{{ dbt_utils.generate_surrogate_key(['employeeNumber']) }}` to generate the surrogate key.\n",
    "\n",
    "Save changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.4.4. Open the `schema.yml` file and based on the `dim_customers` schema, create the schema for the `dim_employees` table. The `employee_key` should be the primary key for this table, because I will set the same tests as in `dim_customers`. Using the appropriate column names is important."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-5'></a>\n",
    "### 3.5 - Creating the Office Dimension Table\n",
    "\n",
    "3.5.1. This is the query to create the dimension table `dim_offices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>office_key</th>\n",
       "        <th>postal_code</th>\n",
       "        <th>city</th>\n",
       "        <th>state</th>\n",
       "        <th>country</th>\n",
       "        <th>territory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>94080</td>\n",
       "        <td>San Francisco</td>\n",
       "        <td>CA</td>\n",
       "        <td>USA</td>\n",
       "        <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>02107</td>\n",
       "        <td>Boston</td>\n",
       "        <td>MA</td>\n",
       "        <td>USA</td>\n",
       "        <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>10022</td>\n",
       "        <td>NYC</td>\n",
       "        <td>NY</td>\n",
       "        <td>USA</td>\n",
       "        <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4</td>\n",
       "        <td>75017</td>\n",
       "        <td>Paris</td>\n",
       "        <td>None</td>\n",
       "        <td>France</td>\n",
       "        <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>5</td>\n",
       "        <td>102-8578</td>\n",
       "        <td>Tokyo</td>\n",
       "        <td>Chiyoda-Ku</td>\n",
       "        <td>Japan</td>\n",
       "        <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>2010</td>\n",
       "        <td>Sydney</td>\n",
       "        <td>NSW</td>\n",
       "        <td>Australia</td>\n",
       "        <td>APAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "        <td>EC2N 1HN</td>\n",
       "        <td>London</td>\n",
       "        <td>None</td>\n",
       "        <td>UK</td>\n",
       "        <td>EMEA</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1', '94080', 'San Francisco', 'CA', 'USA', 'NA'),\n",
       " ('2', '02107', 'Boston', 'MA', 'USA', 'NA'),\n",
       " ('3', '10022', 'NYC', 'NY', 'USA', 'NA'),\n",
       " ('4', '75017', 'Paris', None, 'France', 'EMEA'),\n",
       " ('5', '102-8578', 'Tokyo', 'Chiyoda-Ku', 'Japan', 'Japan'),\n",
       " ('6', '2010', 'Sydney', 'NSW', 'Australia', 'APAC'),\n",
       " ('7', 'EC2N 1HN', 'London', None, 'UK', 'EMEA')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    officeCode as office_key, \n",
    "    postalCode as postal_code, \n",
    "    city as city, \n",
    "    state as state, \n",
    "    country as country, \n",
    "    territory as territory\n",
    "FROM classicmodels.offices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.2. Go to the folder `./classicmodels_modeling/models/star_schema/` and create an SQL file `dim_offices.sql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.3. Copy the previous query, paste it into the new file `dim_offices.sql`. Make the following changes in the file:\n",
    "\n",
    "- Replace `classicmodels` with `{{var(\"source_schema\")}}` (in 1 place).\n",
    "- Replace `officeCode` with `{{ dbt_utils.generate_surrogate_key(['officeCode']) }}` to generate the surrogate key.\n",
    "\n",
    "Save changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.5.4. Open the `schema.yml` file and based on the `dim_customers` schema, create the schema for the `dim_offices` table. The `office_key` should be the primary key for this table, because i will set the same tests as in `dim_customers`. Using the appropriate column names is important."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-6'></a>\n",
    "### 3.6 - Creating the Product Dimension Table\n",
    "\n",
    "3.6.1. This is the query to create the dimension table `dim_products`. Use `LIMIT` as the total output has 110 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>product_key</th>\n",
       "        <th>product_name</th>\n",
       "        <th>product_line</th>\n",
       "        <th>product_scale</th>\n",
       "        <th>product_vendor</th>\n",
       "        <th>product_description</th>\n",
       "        <th>product_line_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>S10_1678</td>\n",
       "        <td>1969 Harley Davidson Ultimate Chopper</td>\n",
       "        <td>Motorcycles</td>\n",
       "        <td>1:10</td>\n",
       "        <td>Min Lin Diecast</td>\n",
       "        <td>This replica features working kickstand, front suspension, gear-shift lever, footbrake lever, drive chain, wheels and steering. All parts are particularly delicate due to their precise scale and require special care and attention.</td>\n",
       "        <td>Our motorcycles are state of the art replicas of classic as well as contemporary motorcycle legends such as Harley Davidson, Ducati and Vespa. Models contain stunning details such as official logos, rotating wheels, working kickstand, front suspension, gear-shift lever, footbrake lever, and drive chain. Materials used include diecast and plastic. The models range in size from 1:10 to 1:50 scale and include numerous limited edition and several out-of-production vehicles. All models come fully assembled and ready for display in the home or office. Most include a certificate of authenticity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>S10_1949</td>\n",
       "        <td>1952 Alpine Renault 1300</td>\n",
       "        <td>Classic Cars</td>\n",
       "        <td>1:10</td>\n",
       "        <td>Classic Metal Creations</td>\n",
       "        <td>Turnable front wheels; steering function; detailed interior; detailed engine; opening hood; opening trunk; opening doors; and detailed chassis.</td>\n",
       "        <td>Attention car enthusiasts: Make your wildest car ownership dreams come true. Whether you are looking for classic muscle cars, dream sports cars or movie-inspired miniatures, you will find great choices in this category. These replicas feature superb attention to detail and craftsmanship and offer features such as working steering system, opening forward compartment, opening rear trunk with removable spare wheel, 4-wheel independent spring suspension, and so on. The models range in size from 1:10 to 1:24 scale and include numerous limited edition and several out-of-production vehicles. All models include a certificate of authenticity from their manufacturers and come fully assembled and ready for display in the home or office.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>S10_2016</td>\n",
       "        <td>1996 Moto Guzzi 1100i</td>\n",
       "        <td>Motorcycles</td>\n",
       "        <td>1:10</td>\n",
       "        <td>Highway 66 Mini Classics</td>\n",
       "        <td>Official Moto Guzzi logos and insignias, saddle bags located on side of motorcycle, detailed engine, working steering, working suspension, two leather seats, luggage rack, dual exhaust pipes, small saddle bag located on handle bars, two-tone paint with chrome accents, superior die-cast detail , rotating wheels , working kick stand, diecast metal with plastic parts and baked enamel finish.</td>\n",
       "        <td>Our motorcycles are state of the art replicas of classic as well as contemporary motorcycle legends such as Harley Davidson, Ducati and Vespa. Models contain stunning details such as official logos, rotating wheels, working kickstand, front suspension, gear-shift lever, footbrake lever, and drive chain. Materials used include diecast and plastic. The models range in size from 1:10 to 1:50 scale and include numerous limited edition and several out-of-production vehicles. All models come fully assembled and ready for display in the home or office. Most include a certificate of authenticity.</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('S10_1678', '1969 Harley Davidson Ultimate Chopper', 'Motorcycles', '1:10', 'Min Lin Diecast', 'This replica features working kickstand, front suspension, gear-shift lever, footbrake lever, drive chain, wheels and steering. All parts are particularly delicate due to their precise scale and require special care and attention.', 'Our motorcycles are state of the art replicas of classic as well as contemporary motorcycle legends such as Harley Davidson, Ducati and Vespa. Models ... (297 characters truncated) ...  out-of-production vehicles. All models come fully assembled and ready for display in the home or office. Most include a certificate of authenticity.'),\n",
       " ('S10_1949', '1952 Alpine Renault 1300', 'Classic Cars', '1:10', 'Classic Metal Creations', 'Turnable front wheels; steering function; detailed interior; detailed engine; opening hood; opening trunk; opening doors; and detailed chassis.', 'Attention car enthusiasts: Make your wildest car ownership dreams come true. Whether you are looking for classic muscle cars, dream sports cars or mo ... (437 characters truncated) ... cles. All models include a certificate of authenticity from their manufacturers and come fully assembled and ready for display in the home or office.'),\n",
       " ('S10_2016', '1996 Moto Guzzi 1100i', 'Motorcycles', '1:10', 'Highway 66 Mini Classics', 'Official Moto Guzzi logos and insignias, saddle bags located on side of motorcycle, detailed engine, working steering, working suspension, two leathe ... (93 characters truncated) ... paint with chrome accents, superior die-cast detail , rotating wheels , working kick stand, diecast metal with plastic parts and baked enamel finish.', 'Our motorcycles are state of the art replicas of classic as well as contemporary motorcycle legends such as Harley Davidson, Ducati and Vespa. Models ... (297 characters truncated) ...  out-of-production vehicles. All models come fully assembled and ready for display in the home or office. Most include a certificate of authenticity.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    productCode as product_key, \n",
    "    productName as product_name, \n",
    "    products.productLine as product_line, \n",
    "    productScale as product_scale, \n",
    "    productVendor as product_vendor,\n",
    "    productDescription as product_description, \n",
    "    textDescription as product_line_description\n",
    "FROM classicmodels.products\n",
    "JOIN classicmodels.productlines ON products.productLine=productlines.productLine\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.2. Create an SQL file `dim_products.sql` in the folder `./classicmodels_modeling/models/star_schema/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.3. Copy the previous query, paste it into the new file `dim_products.sql`. Make the following changes in the file:\n",
    "\n",
    "- Replace `classicmodels` with `{{var(\"source_schema\")}}` (in 2 places).\n",
    "- Replace `productCode` with `{{ dbt_utils.generate_surrogate_key(['productCode']) }}` to generate the surrogate key.\n",
    "\n",
    "Save changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "3.6.4. Open the `schema.yml` file and based on the `dim_customers` schema, create the schema for the `dim_products` table. The `product_key` should be the primary key for this table, in order to set the same tests as in `dim_customers`. Using the appropriate column names is important."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-7'></a>\n",
    "### 3.7 - Creating the Date Dimension Table\n",
    "\n",
    "Time is one of the most important dimensions in star schemas, for this case, I limit the time dimension to the dates that appear in the `orders` table. Generating this dimension can be cumbersome, so I make use of the `dbt_date` package to generate the date dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.1. Create a `dates.sql` model file in the `./classicmodels_modeling/models/star_schema/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.2. Inside of it, add the line to call the `get_date_dimension` function from the `dbt_date` package. This function takes an initial and final date, for `classicmodels` the dates are between the start of 2003 and the end of 2005. Here is the format of the function call:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "{{ dbt_date.get_date_dimension(\"YYYY-MM-DD\", \"YYYY-MM-DD\") }}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.3. Create a `dim_dates.sql` model file in the `./classicmodels_modeling/models/star_schema/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.4. In `dim_dates.sql` write the following SQL query to select required columns from the `date_dimension` model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT\n",
    "    date_day,\n",
    "    day_of_week,\n",
    "    day_of_month,\n",
    "    day_of_year,\n",
    "    week_of_year,\n",
    "    month_of_year,\n",
    "    month_name,\n",
    "    quarter_of_year,\n",
    "    year_number\n",
    "FROM\n",
    "    date_dimension d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the `date` model, add a CTE statement prior to that `SELECT` statement (at the start of the file):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "with date_dimension as (\n",
    "    select * from {{ ref('dates') }}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save changes to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.5. Open the `schema.yml` file and add the following schema for the `dim_dates` table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "  - name: dim_dates\n",
    "    columns:\n",
    "      - name: date_day\n",
    "        description: The primary key for this table\n",
    "        data_tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "      - name: day_of_week\n",
    "      - name: day_of_month\n",
    "      - name: day_of_year\n",
    "      - name: week_of_year\n",
    "      - name: month_of_year\n",
    "      - name: month_name\n",
    "      - name: quarter_of_year\n",
    "      - name: year_number\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-8'></a>\n",
    "### 3.8 - Running the Star Schema Model\n",
    "\n",
    "Once  all the models for the star schema, it is time to run `dbt` against the database to create the proposed star schema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8.1. In the terminal, make sure to set the `dbt` project folder as your working directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /home/coder/project/classicmodels_modeling\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8.2. Once you are in the `~/project/classicmodels_modeling` folder in the terminal, then run `dbt` with the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt run -s star_schema\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should run your models and perform the creation and population of the tables in a new database named `classicmodels_star_schema` that resides in the same RDS server. Given that you are going to create several models with `dbt`, the `-s` (or `--select`) option allows you to select the particular data model that you want to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8.7. Now, it is time to check if the tables were created and populated. Run the next cell to change the connection to the `classicmodels_star_schema` database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>table_catalog</th>\n",
       "        <th>table_schema</th>\n",
       "        <th>table_name</th>\n",
       "        <th>table_type</th>\n",
       "        <th>self_referencing_column_name</th>\n",
       "        <th>reference_generation</th>\n",
       "        <th>user_defined_type_catalog</th>\n",
       "        <th>user_defined_type_schema</th>\n",
       "        <th>user_defined_type_name</th>\n",
       "        <th>is_insertable_into</th>\n",
       "        <th>is_typed</th>\n",
       "        <th>commit_action</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>dim_dates</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>dates</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>dim_customers</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>dim_employees</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>dim_offices</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>dim_products</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_star_schema</td>\n",
       "        <td>fact_orders</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('postgres', 'classicmodels_star_schema', 'dim_dates', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels_star_schema', 'dates', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels_star_schema', 'dim_customers', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels_star_schema', 'dim_employees', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels_star_schema', 'dim_offices', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels_star_schema', 'dim_products', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None),\n",
       " ('postgres', 'classicmodels_star_schema', 'fact_orders', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM information_schema.tables \n",
    "WHERE table_schema = 'classicmodels_star_schema'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count the number of rows in each table to verify that they were populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "exercise": [
     "ex01"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2996</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2996,)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_star_schema.fact_orders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 2996     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "exercise": [
     "ex02"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>122</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(122,)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_star_schema.dim_customers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 122       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "exercise": [
     "ex03"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>23</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(23,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_star_schema.dim_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 23        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "exercise": [
     "ex04"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(7,)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_star_schema.dim_offices;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 7         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "exercise": [
     "ex05"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>110</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(110,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_star_schema.dim_products;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 110       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "exercise": [
     "ex06"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1095</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1095,)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_star_schema.dim_dates;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 1095      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4 - One Big Table (OBT)\n",
    "\n",
    "As the name suggests, it means a large table containing all the relevant data needed for analysis. It is similar to a fact table, but instead of using dimensional tables and foreign keys, it contains the required dimensional values for each row within. This approach ensures the data warehouse doesn't have to perform any joins to query the relevant data each time the data is needed. Here is an example of an OBT table focused on the orders of `classicmodels`:\n",
    "\n",
    "![image](images/obt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "4.1. Create the file `orders_obt.sql` in the `./classicmodels_modeling/models/obt/` folder. Here is the SQL query to which is needed to apply jinja templating like in [Section 3](#3). No need to create any surrogate keys there."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>order_number</th>\n",
       "        <th>order_line_number</th>\n",
       "        <th>product_name</th>\n",
       "        <th>product_scale</th>\n",
       "        <th>product_vendor</th>\n",
       "        <th>product_description</th>\n",
       "        <th>product_buy_price</th>\n",
       "        <th>product_msrp</th>\n",
       "        <th>product_line</th>\n",
       "        <th>quantity_ordered</th>\n",
       "        <th>product_price</th>\n",
       "        <th>order_date</th>\n",
       "        <th>order_required_date</th>\n",
       "        <th>order_shipped_date</th>\n",
       "        <th>customer_name</th>\n",
       "        <th>customer_city</th>\n",
       "        <th>customer_state</th>\n",
       "        <th>customer_postal_code</th>\n",
       "        <th>customer_credit_limit</th>\n",
       "        <th>sales_rep_first_name</th>\n",
       "        <th>sales_rep_last_name</th>\n",
       "        <th>sales_rep_title</th>\n",
       "        <th>order_status</th>\n",
       "        <th>order_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10100</td>\n",
       "        <td>3</td>\n",
       "        <td>1917 Grand Touring Sedan</td>\n",
       "        <td>1:18</td>\n",
       "        <td>Welly Diecast Productions</td>\n",
       "        <td>This 1:18 scale replica of the 1917 Grand Touring car has all the features you would expect from museum quality reproductions: all four doors and bi-fold hood opening, detailed engine and instrument panel, chrome-look trim, and tufted upholstery, all topped off with a factory baked-enamel finish.</td>\n",
       "        <td>86.7</td>\n",
       "        <td>170</td>\n",
       "        <td>Our Vintage Car models realistically portray automobiles produced from the early 1900s through the 1940s. Materials used include Bakelite, diecast, plastic and wood. Most of the replicas are in the 1:18 and 1:24 scale sizes, which provide the optimum in detail and accuracy. Prices range from $30.00 up to $180.00 for some special limited edition replicas. All models include a certificate of authenticity from their manufacturers and come fully assembled and ready for display in the home or office.</td>\n",
       "        <td>30</td>\n",
       "        <td>136</td>\n",
       "        <td>2003-01-06 00:00:00</td>\n",
       "        <td>2003-01-13 00:00:00</td>\n",
       "        <td>2003-01-10 00:00:00</td>\n",
       "        <td>Online Diecast Creations Co.</td>\n",
       "        <td>Nashua</td>\n",
       "        <td>NH</td>\n",
       "        <td>62005</td>\n",
       "        <td>114200</td>\n",
       "        <td>Steve</td>\n",
       "        <td>Patterson</td>\n",
       "        <td>Sales Rep</td>\n",
       "        <td>Shipped</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10100</td>\n",
       "        <td>2</td>\n",
       "        <td>1911 Ford Town Car</td>\n",
       "        <td>1:18</td>\n",
       "        <td>Motor City Art Classics</td>\n",
       "        <td>Features opening hood, opening doors, opening trunk, wide white wall tires, front door arm rests, working steering system.</td>\n",
       "        <td>33.3</td>\n",
       "        <td>60.54</td>\n",
       "        <td>Our Vintage Car models realistically portray automobiles produced from the early 1900s through the 1940s. Materials used include Bakelite, diecast, plastic and wood. Most of the replicas are in the 1:18 and 1:24 scale sizes, which provide the optimum in detail and accuracy. Prices range from $30.00 up to $180.00 for some special limited edition replicas. All models include a certificate of authenticity from their manufacturers and come fully assembled and ready for display in the home or office.</td>\n",
       "        <td>50</td>\n",
       "        <td>55.09</td>\n",
       "        <td>2003-01-06 00:00:00</td>\n",
       "        <td>2003-01-13 00:00:00</td>\n",
       "        <td>2003-01-10 00:00:00</td>\n",
       "        <td>Online Diecast Creations Co.</td>\n",
       "        <td>Nashua</td>\n",
       "        <td>NH</td>\n",
       "        <td>62005</td>\n",
       "        <td>114200</td>\n",
       "        <td>Steve</td>\n",
       "        <td>Patterson</td>\n",
       "        <td>Sales Rep</td>\n",
       "        <td>Shipped</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(10100, 3, '1917 Grand Touring Sedan', '1:18', 'Welly Diecast Productions', 'This 1:18 scale replica of the 1917 Grand Touring car has all the features you would expect from museum quality reproductions: all four doors and bi-fold hood opening, detailed engine and instrument panel, chrome-look trim, and tufted upholstery, all topped off with a factory baked-enamel finish.', Decimal('86.7'), Decimal('170'), 'Our Vintage Car models realistically portray automobiles produced from the early 1900s through the 1940s. Materials used include Bakelite, diecast, p ... (202 characters truncated) ... icas. All models include a certificate of authenticity from their manufacturers and come fully assembled and ready for display in the home or office.', 30, Decimal('136'), datetime.datetime(2003, 1, 6, 0, 0), datetime.datetime(2003, 1, 13, 0, 0), datetime.datetime(2003, 1, 10, 0, 0), 'Online Diecast Creations Co.', 'Nashua', 'NH', '62005', Decimal('114200'), 'Steve', 'Patterson', 'Sales Rep', 'Shipped', None),\n",
       " (10100, 2, '1911 Ford Town Car', '1:18', 'Motor City Art Classics', 'Features opening hood, opening doors, opening trunk, wide white wall tires, front door arm rests, working steering system.', Decimal('33.3'), Decimal('60.54'), 'Our Vintage Car models realistically portray automobiles produced from the early 1900s through the 1940s. Materials used include Bakelite, diecast, p ... (202 characters truncated) ... icas. All models include a certificate of authenticity from their manufacturers and come fully assembled and ready for display in the home or office.', 50, Decimal('55.09'), datetime.datetime(2003, 1, 6, 0, 0), datetime.datetime(2003, 1, 13, 0, 0), datetime.datetime(2003, 1, 10, 0, 0), 'Online Diecast Creations Co.', 'Nashua', 'NH', '62005', Decimal('114200'), 'Steve', 'Patterson', 'Sales Rep', 'Shipped', None)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    orderdetails.orderNumber as order_number,\n",
    "    orderdetails.orderLineNumber as order_line_number,\n",
    "    products.productName as product_name,\n",
    "    products.productScale as product_scale,\n",
    "    products.productVendor as product_vendor,\n",
    "    products.productDescription as product_description,\n",
    "    products.buyPrice as product_buy_price,\n",
    "    products.MSRP as product_msrp,\n",
    "    productlines.textDescription as product_line,\n",
    "    orderdetails.quantityOrdered as quantity_ordered,\n",
    "    orderdetails.priceEach as product_price,\n",
    "    orders.orderDate as order_date,\n",
    "    orders.requiredDate as order_required_date,\n",
    "    orders.shippedDate as order_shipped_date,\n",
    "    customers.customerName as customer_name,\n",
    "    customers.city as customer_city,\n",
    "    customers.state as customer_state,\n",
    "    customers.postalCode as customer_postal_code,\n",
    "    customers.creditLimit as customer_credit_limit,\n",
    "    employees.firstName as sales_rep_first_name,\n",
    "    employees.lastName as sales_rep_last_name,\n",
    "    employees.jobTitle as sales_rep_title,\n",
    "    orders.status as order_status,\n",
    "    orders.comments as order_comments\n",
    "FROM classicmodels.orderdetails\n",
    "JOIN classicmodels.orders ON orderdetails.orderNumber =  orders.orderNumber\n",
    "JOIN classicmodels.products ON orderdetails.productCode =  products.productCode\n",
    "JOIN classicmodels.productlines ON products.productLine =  productlines.productLine\n",
    "JOIN classicmodels.customers ON orders.customerNumber =  customers.customerNumber\n",
    "JOIN classicmodels.employees ON customers.salesRepEmployeeNumber =  employees.employeeNumber\n",
    "LIMIT 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Create the `schema.yml` file in the `./classicmodels_modeling/models/obt/` folder and add the following schema for the `orders_obt` table:\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: orders_obt\n",
    "    description: \"Orders OBT\"\n",
    "    columns:\n",
    "      - name: order_number\n",
    "        description: Part of the primary key for this table\n",
    "      - name: order_line_number\n",
    "        description: Part of the primary key for this table\n",
    "      - name: product_name\n",
    "      - name: product_scale\n",
    "      - name: product_vendor\n",
    "      - name: product_description\n",
    "      - name: product_buy_price\n",
    "      - name: product_msrp\n",
    "      - name: product_line\n",
    "      - name: quantity_ordered\n",
    "      - name: product_price\n",
    "      - name: order_date\n",
    "      - name: order_required_date\n",
    "      - name: order_shipped_date\n",
    "      - name: customer_name\n",
    "      - name: customer_city\n",
    "      - name: customer_state\n",
    "      - name: customer_postal_code\n",
    "      - name: customer_credit_limit\n",
    "      - name: sales_rep_first_name\n",
    "      - name: sales_rep_title\n",
    "      - name: order_status\n",
    "      - name: order_comments\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In the next section, I added the test column will are needed to test the model."
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3. Open the `./classicmodels_modeling/dbt_project.yml` file, at the end of it, under the `classicmodels_modeling` key (which is nested inside the `models` key), add the following lines:\n",
    "\n",
    "```yml\n",
    "    obt:\n",
    "      +materialized: table\n",
    "      +schema: obt\n",
    "```\n",
    "\n",
    "Save changes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4. Make sure you are in the `~/project/classicmodels_modeling` folder in the terminal. Run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "dbt run --select \"obt\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5. Once you run the dbt run statement, verify that the tables exist and do a record count for each table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "SqlCellData": {
     "variableName$1": "df_sql9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>table_catalog</th>\n",
       "        <th>table_schema</th>\n",
       "        <th>table_name</th>\n",
       "        <th>table_type</th>\n",
       "        <th>self_referencing_column_name</th>\n",
       "        <th>reference_generation</th>\n",
       "        <th>user_defined_type_catalog</th>\n",
       "        <th>user_defined_type_schema</th>\n",
       "        <th>user_defined_type_name</th>\n",
       "        <th>is_insertable_into</th>\n",
       "        <th>is_typed</th>\n",
       "        <th>commit_action</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>classicmodels_obt</td>\n",
       "        <td>orders_obt</td>\n",
       "        <td>BASE TABLE</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>YES</td>\n",
       "        <td>NO</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('postgres', 'classicmodels_obt', 'orders_obt', 'BASE TABLE', None, None, None, None, None, 'YES', 'NO', None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM information_schema.tables \n",
    "WHERE table_schema = 'classicmodels_obt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "exercise": [
     "ex07"
    ],
    "tags": [
     "graded"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://postgresuser:***@de-c4w1a1-rds.c5g8aey68kpg.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2996</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2996,)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM classicmodels_obt.orders_obt;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **count** |\n",
    "| --------- |\n",
    "| 2996      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 5 - Performing Tests over the Data in the New Models\n",
    "\n",
    "I did perform some tests over the data that was populated in your new star schema model. In the `schema.yml` file I have the definition for each model and each column. I place certain tests at the column level or at the table level. As an example of tests at the table level, I did define the following one for the `orders_obt` table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "- name: orders_obt\n",
    "  description: \"Orders OBT\"\n",
    "  columns:\n",
    "    ...\n",
    "  data_tests:\n",
    "    - dbt_utils.unique_combination_of_columns:\n",
    "        combination_of_columns:\n",
    "        - order_number\n",
    "        - order_line_number\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: The indentation in `.yml` files is crucial for the correct interpretation of the file. Ensure that the indentation levels are consistent to avoid errors in processing the `YAML` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test verifies that the combination of columns that form the primary key is unique. Note that this primary key is composed by a combination of 2 columns. To check for the primary key on other tables that are non composed keys, you can define the test at the column level, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "- name: dim_customers\n",
    "  description: \"Customer dimension\"\n",
    "  columns:\n",
    "    - name: customer_key\n",
    "      description: The primary key for this table\n",
    "      data_tests:\n",
    "        - unique\n",
    "        - not_null\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add those tests to your model and run the `dbt test` command to check them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt test -s obt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In this project, I demonstrated the capabilities of  `dbt` and expansiate on data modeling, each data model has its advantages and setbacks and should be used based on the business and analytical requirements. OBT performs faster in terms of data retrieval speed when compared against a star schema, however updating OBT could be much more complex and a star schema is better in terms of conceptualizing and sharing your data while requiring less storage space."
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
